
##This is my Google Colab version of simple CNN dogs vs cats. The dataset is from Kaggle and mounted via Google Drive. I also fixed the dimensions problem with adding 
## conv2d and maxpool layers

### To run this code without graph execution error you need to have your GPU on. 

##Packages
```
import pandas as pd
import matplotlib.pyplot as plt
import os
import cv2
import tensorflow as tf
import numpy as np
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Flatten, Dropout, Activation, Conv2D, MaxPooling2D
```
##Drive with dataset.
```
from google.colab import drive
drive.mount('/content/drive')
```

##First you need to access unzipped files on your drive. The dataset is made of 2 folders; train and test1 (in my code it will be train1). After that we split file names 
##with ".". Convert pixels into array in grayscale, resize and display one image. It must be square but values can change.

```
main_dir = "./drive/MyDrive/dogs-vs-cats.zip (Unzipped Files)"
train_dir = "train1"
path = os.path.join(main_dir,train_dir)

for p in os.listdir(path):
    category = p.split(".")[0]
    img_array = cv2.imread(os.path.join(path,p),cv2.IMREAD_GRAYSCALE)
    new_img_array = cv2.resize(img_array, dsize=(80, 80))
    plt.imshow(new_img_array,cmap="gray")
    break
```

##Now we declare trainning and target array and assign 1 or 0 in order if it is a cat or dog

```
X = []
y = []
convert = lambda category : int(category == 'dog')
def create_test_data(path):
    for p in os.listdir(path):
        category = p.split(".")[0]
        category = convert(category)
        img_array = cv2.imread(os.path.join(path,p),cv2.IMREAD_GRAYSCALE)
        new_img_array = cv2.resize(img_array, dsize=(80, 80))
        X.append(new_img_array)
        y.append(category)
```

##Reshape for Conv2d layer. It may take some time, in my case 2h.

```
create_test_data(path)
X = np.array(X).reshape(-1, 80, 80, 1)
y = np.array(y)
```

##Data normalization

```
X = X/255.0
```

##Here i fixed the problem with dimentions which accured during adding layers. Next you just need to add padding and data format. Im not sure if it's Google Colab
##error. 

```
from keras import backend as K
K.set_image_data_format('channels_first')
```

## I used this combination of layers and sigmoid activation with Dense layer to access pobability. You can also use categorical_creossentropy but this works fine 
##as well

```
model = Sequential()
model.add(Conv2D(64,(64,64), activation = 'relu', input_shape = X.shape[1:], padding='same', data_format='channels_first'))
model.add(MaxPooling2D(pool_size = (2,2), padding='same', data_format='channels_last'))
model.add(Conv2D(64,(32,32), activation = 'relu', padding='same', data_format='channels_last'))
model.add(MaxPooling2D(pool_size = (2,2), padding='same', data_format='channels_last'))
model.add(Conv2D(64,(3,3), activation = 'relu', padding='same', data_format='channels_last'))
model.add(MaxPooling2D(pool_size = (2,2), padding='same', data_format='channels_last'))

model.add(Flatten())
model.add(Dense(64, activation='relu'))
model.add(Dense(1, activation='sigmoid'))

model.compile(optimizer="adam",
              loss='binary_crossentropy',
              metrics=['accuracy'])
```

##Now we fit the model. Make sure you have your GPU on, in other case it raised Graph execution problem

```
model.fit(X, y, epochs=10, batch_size=32, validation_split=0.2)
```

##Next step after training data you must prepare test data in the same way

```
train_dir = "test1"
path = os.path.join(main_dir,train_dir)
#os.listdir(path)

X_test = []
id_line = []
def create_test1_data(path):
    for p in os.listdir(path):
        id_line.append(p.split(".")[0])
        img_array = cv2.imread(os.path.join(path,p),cv2.IMREAD_GRAYSCALE)
        new_img_array = cv2.resize(img_array, dsize=(80, 80))
        X_test.append(new_img_array)
create_test1_data(path)
X_test = np.array(X_test).reshape(-1,80,80,1)
X_test = X_test/255
```
##and finally make predictions

```
predictions = model.predict(X_test)
```

##Here you can round predictions and see probability if you choose 'sigmoid' over 'softmax' activation

```
predicted_val = [int(round(p[0])) for p in predictions]
```
##submit resultset
```
submission_df = pd.DataFrame({'id':id_line, 'label':predicted_val})
```
##and save as csv file
```
submission_df.to_csv("submission.csv", index=False)
```
##Thanks!






